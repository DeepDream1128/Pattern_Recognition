{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.datasets import SPEECHCOMMANDS\n",
    "import os\n",
    "\n",
    "\n",
    "class SubsetSC(SPEECHCOMMANDS):\n",
    "    def __init__(self, subset: str = None):\n",
    "        super().__init__(\"./\", download=True)\n",
    "\n",
    "        def load_list(filename):\n",
    "            filepath = os.path.join(self._path, filename)\n",
    "            with open(filepath) as fileobj:\n",
    "                return [os.path.normpath(os.path.join(self._path, line.strip())) for line in fileobj]\n",
    "\n",
    "        if subset == \"validation\":\n",
    "            self._walker = load_list(\"validation_list.txt\")\n",
    "        elif subset == \"testing\":\n",
    "            self._walker = load_list(\"testing_list.txt\")\n",
    "        elif subset == \"training\":\n",
    "            excludes = load_list(\"validation_list.txt\") + load_list(\"testing_list.txt\")\n",
    "            excludes = set(excludes)\n",
    "            self._walker = [w for w in self._walker if w not in excludes]\n",
    "            # 筛选代表数字的音频文件\n",
    "        digits = ['zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine']\n",
    "        self._walker = [w for w in self._walker if any(digit in w for digit in digits)]\n",
    "        self.labels = []\n",
    "    def collect_labels(self):\n",
    "        # 收集所有唯一的标签\n",
    "        for _, _, label, _, _ in self:\n",
    "            if label not in self.labels:\n",
    "                self.labels.append(label)\n",
    "        self.labels.sort()\n",
    "\n",
    "# # Create training and testing split of the data. We do not use validation in this tutorial.\n",
    "# train_set = SubsetSC(\"training\")\n",
    "# test_set = SubsetSC(\"testing\")\n",
    "\n",
    "# waveform, sample_rate, label, speaker_id, utterance_number = train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set labels: ['eight', 'five', 'four', 'nine', 'one', 'seven', 'six', 'three', 'two', 'zero']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchaudio.transforms as T\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "sample_rate=16000\n",
    "new_sample_rate = 8000\n",
    "transform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=new_sample_rate)\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # 初始化特征和标签列表\n",
    "    inputs, labels = [], []\n",
    "\n",
    "    # 定义一个临时列表来存储所有波形的长度\n",
    "    lengths = []\n",
    "\n",
    "    # 提取波形和标签\n",
    "    for waveform, _, label, _, _ in batch:\n",
    "        lengths.append(waveform.size(1))\n",
    "        inputs.append(waveform.squeeze(0)) \n",
    "        labels.append(label)\n",
    "\n",
    "    # 找到最大的波形长度\n",
    "    max_len = max(lengths)\n",
    "\n",
    "    # Pad输入波形到相同的长度\n",
    "    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "\n",
    "    # 将标签转换为张量\n",
    "    label_to_index = {label: index for index, label in enumerate(sorted(set(labels)))}\n",
    "    labels_indices = torch.tensor([label_to_index[label] for label in labels])\n",
    "\n",
    "    return inputs_padded, labels_indices\n",
    "\n",
    "# all_data = SubsetSC(subset=None)  # 加载所有数据\n",
    "# total_size = len(all_data)\n",
    "# train_size = int(total_size * 0.8)\n",
    "# test_size = total_size - train_size\n",
    "# train_dataset, test_dataset = random_split(all_data, [train_size, test_size])\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "# train_dataset, test_dataset = random_split(all_data, [train_size, test_size])\n",
    "\n",
    "# 使用SubsetSC类和collate_fn来创建DataLoader\n",
    "if device == \"cuda\":\n",
    "    num_workers = 16\n",
    "    pin_memory = True\n",
    "else:\n",
    "    num_workers = 0\n",
    "    pin_memory = False\n",
    "train_set = SubsetSC(subset='training')\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, collate_fn=collate_fn, num_workers=num_workers, pin_memory=pin_memory)\n",
    "val_set = SubsetSC(subset='validation')\n",
    "val_loader = DataLoader(val_set, batch_size=64, shuffle=True, collate_fn=collate_fn, num_workers=num_workers, pin_memory=pin_memory)\n",
    "test_set = SubsetSC(subset='testing')\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False, collate_fn=collate_fn, num_workers=num_workers, pin_memory=pin_memory)\n",
    "\n",
    "train_set.collect_labels()\n",
    "print(\"Training set labels:\", train_set.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Perceptron(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(Perceptron, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# 参数设置\n",
    "input_size =  16000\n",
    "hidden_size = 64\n",
    "num_classes = 10 \n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "best_accuracy = 0.0\n",
    "# 模型、损失函数和优化器\n",
    "model = Perceptron(input_size, num_classes)\n",
    "model.to(device)\n",
    "# model = MLP(input_size, hidden_size, num_classes).to(device)\n",
    "print(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 训练过程...\n",
    "    model.train()  # 确保模型处于训练模式\n",
    "    for i, (features, labels) in enumerate(train_loader):\n",
    "        \n",
    "        labels=labels.to(device)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        features=features.to(device)\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # 验证过程\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features=features.to(device)\n",
    "            labels=labels.to(device)\n",
    "            features = features.view(features.size(0), -1)\n",
    "            outputs = model(features)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    # 检查是否为最佳模型，并保存\n",
    "    if accuracy > best_accuracy:\n",
    "        print(f\"Found better model at epoch {epoch+1} with accuracy {accuracy:.4f}. Saving model...\")\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), 'best_model_accuracy.pt')  # 保存最佳模型的权重\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test set: 10.372534696859022 %\n"
     ]
    }
   ],
   "source": [
    "# 测试模型\n",
    "model.load_state_dict(torch.load('best_model_accuracy.pt'))\n",
    "\n",
    "model.eval()  # 设置模型为评估模式\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for features, labels in test_loader:\n",
    "        features=features.to(device)\n",
    "        labels=labels.to(device)\n",
    "        features = features.view(features.size(0), -1)\n",
    "        outputs = model(features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Accuracy of the model on the test set: {100 * correct / total} %')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
