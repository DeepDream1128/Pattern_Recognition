{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detect as dt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from model import Net  # Make sure to place model.py in your working directory\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取图像并分割\n",
    "image_path = './test/carplate2.png'\n",
    "plt.imshow(cv2.imread(image_path))\n",
    "mats = dt.segment_plate_chars(image_path)\n",
    "print(len(mats))\n",
    "# for img in mats:\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('./mnist_cnn.pt', map_location=torch.device('cuda')))\n",
    "model.eval()  # 设置为评估模式\n",
    "\n",
    "# 定义转换操作，以适应模型训练时的图像格式\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # 将numpy数组转换为PIL图像\n",
    "    transforms.Resize((28, 28)),  # 将图像大小调整为28x28像素\n",
    "    transforms.ToTensor(),  # 将PIL图像转换为PyTorch张量\n",
    "    transforms.Normalize((0.3,), (0.16,))  # 标准化，这些值用于MNIST图像\n",
    "])\n",
    "\n",
    "# 推理函数\n",
    "def infer_character(model, image_np):\n",
    "    # 确保图像是单通道的灰度图\n",
    "    if len(image_np.shape) == 3 and image_np.shape[2] == 3:\n",
    "        image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY)\n",
    "        image_np = dt.resize_with_padding(image_np, 28,28,target_value=image_np[0,0])\n",
    "        # print(image_np[0,0])\n",
    "        if image_np[0,0] >200:\n",
    "            image_np = cv2.bitwise_not(image_np)\n",
    "        \n",
    "    # 将numpy图像转换为PIL图像，然后应用定义好的转换操作\n",
    "    image_tensor = transform(image_np)\n",
    "    image_tensor = image_tensor.unsqueeze(0)  # 添加一个批处理维度\n",
    "\n",
    "    # 执行推理\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        print(F.softmax(output, dim=1).max())\n",
    "        if F.softmax(output, dim=1).max() < 0.9:\n",
    "            return -1\n",
    "        prediction = output.argmax(dim=1, keepdim=True)  # 获得最大概率的索引\n",
    "        # 输出概率\n",
    "        \n",
    "        \n",
    "    return prediction.item()\n",
    "\n",
    "\n",
    "# 预测车牌号\n",
    "plate_number = ''\n",
    "for image_np in mats:  # 假设mats是一个包含了所有字符图像的numpy数组列表\n",
    "    digit = infer_character(model, image_np)\n",
    "    # plt.imshow(image_np)\n",
    "    # plt.show()\n",
    "    plate_number += str(digit) if digit >= 0 else 'X'\n",
    "\n",
    "print('车牌号码是:', plate_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# mat2vector函数的Python版本\n",
    "def mat2vector(data):\n",
    "    if len(data.shape) > 2:\n",
    "        data = cv2.cvtColor(data, cv2.COLOR_BGR2GRAY)\n",
    "    return data.flatten()\n",
    "\n",
    "def template_matching(sample, templates):\n",
    "    distances = cdist(sample, templates, 'euclidean')\n",
    "    min_distance = np.min(distances)\n",
    "    best_match = np.argmin(distances)\n",
    "    return min_distance, best_match\n",
    "\n",
    "# 读取模板并将其转化为向量\n",
    "templates = []\n",
    "for i in range(10):\n",
    "    filename = f'./tamplates/char_{i}.png' \n",
    "    template = cv2.imread(filename, 0)\n",
    "    template = cv2.resize(template, (28, 28))\n",
    "    templates.append(mat2vector(template))\n",
    "\n",
    "templates = np.array(templates)\n",
    "\n",
    "# 测试样本\n",
    "correct_num = 0\n",
    "plate_number = ''\n",
    "for sample in mats:\n",
    "    sample = cv2.resize(sample, (28, 28))\n",
    "    sample_vector = mat2vector(sample).reshape(1, -1)\n",
    "\n",
    "    min_distance, best_match = template_matching(sample_vector, templates)\n",
    "    plate_number += str(best_match) if min_distance < 2000 else 'X'\n",
    "    \n",
    "if plate_number == 'XXXXXXX':\n",
    "    plate_number = ''\n",
    "    for sample in mats:\n",
    "        sample = cv2.resize(sample, (28, 28))\n",
    "        sample = cv2.bitwise_not(sample)\n",
    "        sample_vector = mat2vector(sample).reshape(1, -1)\n",
    "\n",
    "        min_distance, best_match = template_matching(sample_vector, templates)\n",
    "        plate_number += str(best_match) if min_distance < 2000 else 'X'\n",
    "    \n",
    "print('车牌号码是:', plate_number)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "templates = {}\n",
    "for i in range(10):\n",
    "    templates[i] = []  \n",
    "\n",
    "N = 50 \n",
    "for image, label in train_dataset:\n",
    "    if len(templates[label]) < N:\n",
    "        image = image.numpy().squeeze()\n",
    "        templates[label].append(image)\n",
    "    if all(len(templates[digit]) == N for digit in range(10)):\n",
    "        break \n",
    "    \n",
    "# for filename in os.listdir('./tamplates'):\n",
    "#     if filename.endswith(\".png\"):  # 假设所有图像都是PNG格式\n",
    "#         # 读取图像文件\n",
    "#         image_path = os.path.join('./tamplates', filename)\n",
    "#         image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "#         image = cv2.resize(image, (28, 28))\n",
    "#         image = image.squeeze()\n",
    "#         label = int(image_path.split('_')[1].split('.')[0])\n",
    "#         templates[label].append(image)\n",
    "        \n",
    "def match_template(image, templates):\n",
    "    image = image.numpy().squeeze()\n",
    "    matching_scores = []\n",
    "\n",
    "    for digit, temps in templates.items():\n",
    "        for temp in temps:\n",
    "            res = cv2.matchTemplate(image, temp, cv2.TM_CCOEFF)\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "            matching_scores.append((max_val, digit))\n",
    "    matching_scores.sort(key=lambda x: x[0], reverse=True)\n",
    "    return matching_scores[0][1]\n",
    "\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "for image, true_label in test_dataset:\n",
    "    predicted_label = match_template(image, templates)\n",
    "    if predicted_label == true_label:\n",
    "        correct_predictions += 1\n",
    "    total_predictions += 1\n",
    "\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f'Accuracy in MNIST by Matchtemplate: {accuracy * 100:.2f}%')\n",
    "\n",
    "\n",
    "# 文件夹路径\n",
    "folder_path = './test_carplate_num/'\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "# 遍历文件夹\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".png\"):  # 假设所有图像都是PNG格式\n",
    "        # 读取图像文件\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        import detect as dt\n",
    "        image = dt.resize_with_padding(image, 28,28,target_value=image[0,0])\n",
    "        image = torch.tensor(image, dtype=torch.float32) / 255.0  # 归一化\n",
    "\n",
    "        # 对图像应用模板匹配\n",
    "        predicted_label = match_template(image, templates)\n",
    "\n",
    "        # 从文件名获取真实标签（假设文件名以真实数字开头）\n",
    "        true_label = int(filename.split('.')[0])  # 从 \"char_{i}.png\" 中提取数字\n",
    "\n",
    "        # 更新统计\n",
    "        if predicted_label == true_label:\n",
    "            correct_predictions += 1\n",
    "        total_predictions += 1\n",
    "\n",
    "# 计算正确率\n",
    "accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "print(f'Accuracy of Carplate Number by Matchtemplate: {accuracy * 100:.2f}%')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "pic should be Tensor or ndarray. Got <class 'PIL.Image.Image'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m correct_predictions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     44\u001b[0m total_predictions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image, true_label \u001b[38;5;129;01min\u001b[39;00m test_dataset:\n\u001b[1;32m     46\u001b[0m     predicted_label \u001b[38;5;241m=\u001b[39m infer_character(model, image)\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m predicted_label \u001b[38;5;241m==\u001b[39m true_label:\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov5/lib/python3.8/site-packages/torchvision/datasets/mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov5/lib/python3.8/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov5/lib/python3.8/site-packages/torchvision/transforms/transforms.py:234\u001b[0m, in \u001b[0;36mToPILImage.__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[1;32m    226\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m        pic (Tensor or numpy.ndarray): Image to be converted to PIL Image.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    232\u001b[0m \n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pil_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/yolov5/lib/python3.8/site-packages/torchvision/transforms/functional.py:262\u001b[0m, in \u001b[0;36mto_pil_image\u001b[0;34m(pic, mode)\u001b[0m\n\u001b[1;32m    259\u001b[0m     _log_api_usage_once(to_pil_image)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(pic, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pic, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpic should be Tensor or ndarray. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(pic)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pic, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mndimension() \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m}:\n",
      "\u001b[0;31mTypeError\u001b[0m: pic should be Tensor or ndarray. Got <class 'PIL.Image.Image'>."
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('./mnist_cnn.pt', map_location=torch.device('cuda')))\n",
    "model.eval()  # 设置为评估模式\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "# 定义转换操作，以适应模型训练时的图像格式\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # 将numpy数组转换为PIL图像\n",
    "    transforms.Resize((28, 28)),  # 将图像大小调整为28x28像素\n",
    "    transforms.ToTensor(),  # 将PIL图像转换为PyTorch张量\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # 标准化，这些值用于MNIST图像\n",
    "])\n",
    "\n",
    "# 推理函数\n",
    "def infer_character(model, image_np, transform=transform):\n",
    "    # 确保图像是单通道的灰度图\n",
    "    # if len(image_np.shape) == 3 and image_np.shape[2] == 3:\n",
    "    #     image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY)\n",
    "    #     # image_np = dt.resize_with_padding(image_np, 28,28,target_value=image_np[0,0])\n",
    "    #     cv2.resize(image_np, (28, 28))\n",
    "    #     # print(image_np[0,0])\n",
    "    #     if image_np[0,0] >200:\n",
    "    #         image_np = cv2.bitwise_not(image_np)\n",
    "        \n",
    "    # 将numpy图像转换为PIL图像，然后应用定义好的转换操作\n",
    "    \n",
    "    image_tensor = transform(image_np)\n",
    "    image_tensor = image_tensor.unsqueeze(0)  # 添加一个批处理维度\n",
    "\n",
    "    # 执行推理\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        # if F.softmax(output, dim=1).max() < 0.5:\n",
    "        #     return -1\n",
    "        prediction = output.argmax(dim=1, keepdim=True)  # 获得最大概率的索引\n",
    "        # 输出概率\n",
    "        \n",
    "        \n",
    "    return prediction.item()\n",
    "\n",
    "\n",
    "correct_predictions=0\n",
    "total_predictions=0\n",
    "for image, true_label in test_dataset:\n",
    "    predicted_label = infer_character(model, image)\n",
    "    if predicted_label == true_label:\n",
    "        correct_predictions += 1\n",
    "    total_predictions += 1\n",
    "    \n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f'Accuracy in MNIST by CNN: {accuracy * 100:.2f}%')\n",
    "\n",
    "# 文件夹路径\n",
    "folder_path = './test_image/'\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  # 将numpy数组转换为PIL图像\n",
    "    transforms.Resize((28, 28)),  # 将图像大小调整为28x28像素\n",
    "    transforms.ToTensor(),  # 将PIL图像转换为PyTorch张量\n",
    "    # transforms.Normalize((0.3,), (0.16,))  # 标准化，这些值用于MNIST图像\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # 标准化，这些值用于MNIST图像\n",
    "])\n",
    "\n",
    "# 遍历文件夹\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".jpg\"):  # 假设所有图像都是PNG格式\n",
    "        # 读取图像文件\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        import detect as dt\n",
    "        # image = dt.resize_with_padding(image, 28,28,target_value=image[0,0])\n",
    "        # image = cv2.resize(image, (28, 28))\n",
    "        image = cv2.bitwise_not(image)\n",
    "        image = torch.tensor(image, dtype=torch.float32) / 255.0  # 归一化\n",
    "\n",
    "        #应用CNN模型\n",
    "        predicted_label = infer_character(model, image, transform=transform)\n",
    "        \n",
    "\n",
    "        # 从文件名获取真实标签（假设文件名以真实数字开头）\n",
    "        true_label = int(filename.split('.')[0])  # 从 \"{i}.png\" 中提取数字\n",
    "\n",
    "        # 更新统计\n",
    "        if predicted_label == true_label:\n",
    "            correct_predictions += 1\n",
    "        else:\n",
    "            print(f'predicted_label: {predicted_label}, true_label: {true_label}')\n",
    "        total_predictions += 1\n",
    "\n",
    "# 计算正确率\n",
    "accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "print(f'Accuracy of Carplate Number by CNN: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
